{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730861af-bed2-41be-a246-357bb3722a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcc3b0b-6309-4f29-b3e2-7ab0217d55d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Data Preparation\n",
    "# --------------------\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ae4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for 128 images but it takes to long and the results are not really worth unless ypu crank the epochs to 300 but that would take\n",
    "# more than 5 hours of training time and i dont really have that for all datasets\n",
    "#remove 128 from name to use it\n",
    "#transform128 = transforms.Compose([\n",
    "#    transforms.Resize(128),\n",
    "#    transforms.CenterCrop(128),\n",
    "#    transforms.ToTensor(),\n",
    "#    transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff061de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#remove the 128 from the calss name to use\n",
    "#class Discriminator128(nn.Module):\n",
    "#    def __init__(self, img_channels=3):\n",
    "#        super(Discriminator, self).__init__()\n",
    "#        self.model = nn.Sequential(\n",
    "#            nn.Conv2d(img_channels, 32, 4, 2, 1, bias=False),          # 128x128 -> 64x64\n",
    "#            nn.LeakyReLU(0.2, inplace=True),\n",
    "#            nn.Conv2d(32, 64, 4, 2, 1, bias=False),                    # 64x64 -> 32x32\n",
    "#            nn.BatchNorm2d(64),\n",
    "#            nn.LeakyReLU(0.2, inplace=True),\n",
    "#            nn.Conv2d(64, 128, 4, 2, 1, bias=False),                   # 32x32 -> 16x16\n",
    "#            nn.BatchNorm2d(128),\n",
    "#            nn.LeakyReLU(0.2, inplace=True),\n",
    "#            nn.Conv2d(128, 256, 4, 2, 1, bias=False),                  # 16x16 -> 8x8\n",
    "#            nn.BatchNorm2d(256),\n",
    "#            nn.LeakyReLU(0.2, inplace=True),\n",
    "#            nn.Conv2d(256, 512, 4, 2, 1, bias=False),                  # 8x8 -> 4x4\n",
    "#            nn.BatchNorm2d(512),\n",
    "#            nn.LeakyReLU(0.2, inplace=True),\n",
    "#            nn.Conv2d(512, 1, 4, 1, 0, bias=False),                    # 4x4 -> 1x1\n",
    "#            nn.Sigmoid()\n",
    "#        )\n",
    "#\n",
    "#    def forward(self, x):\n",
    "#        return self.model(x).view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad213b10",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#remove 128 from the name to use it\n",
    "#import torch.nn as nn\n",
    "#\n",
    "#class Generator128(nn.Module):\n",
    "#    def __init__(self, latent_dim=100, img_channels=3):\n",
    "#        super(Generator, self).__init__()\n",
    "#        self.model = nn.Sequential(\n",
    "#            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),  # 1x1 -> 4x4\n",
    "#            nn.BatchNorm2d(512),\n",
    "#            nn.ReLU(True),\n",
    "#            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),         # 4x4 -> 8x8\n",
    "#            nn.BatchNorm2d(256),\n",
    "#            nn.ReLU(True),\n",
    "#            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),         # 8x8 -> 16x16\n",
    "#            nn.BatchNorm2d(128),\n",
    "#            nn.ReLU(True),\n",
    "#            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),          # 16x16 -> 32x32\n",
    "#            nn.BatchNorm2d(64),\n",
    "#            nn.ReLU(True),\n",
    "#            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False),           # 32x32 -> 64x64\n",
    "#            nn.BatchNorm2d(32),\n",
    "#            nn.ReLU(True),\n",
    "#            nn.ConvTranspose2d(32, img_channels, 4, 2, 1, bias=False), # 64x64 -> 128x128\n",
    "#            nn.Tanh()\n",
    "#        )\n",
    "#\n",
    "#    def forward(self, x):\n",
    "#        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad97661-0ce4-4234-84fb-51e586439049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to wait fo rall of them to be loaded otherwise it just leads to errors\n",
    "# Load images from dog and cat folders\n",
    "dataset = datasets.ImageFolder(\n",
    "    root='archive/PetImages/',  # Path to the dataset folder\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Print the class-to-label mapping\n",
    "print(dataset.class_to_idx)\n",
    "\n",
    "# this takes a while because it loads all 12k images so it can create a random subset afterwards\n",
    "# you could change it to just load always the first x y images but that could lead to problems \n",
    "# because it always the same images. The model should be trained on random images to make sure it can generalize and not be overtrained\n",
    "# on the same dataset, especially if the epoch becomes higher than 100\n",
    "\n",
    "# Get indices for each class (dog=0, cat=1)\n",
    "dog_indices = [i for i, (_, label) in enumerate(dataset) if label == 1]\n",
    "cat_indices = [i for i, (_, label) in enumerate(dataset) if label == 0]\n",
    "\n",
    "print(\"loaded all Indices\")\n",
    "\n",
    "# Define the exact number of images\n",
    "# 5k:5k for 1:1 10:10\n",
    "# 5k:2.5k for 2:1 10:5\n",
    "# 5k:500 for 10:1\n",
    "# 5k:3.5k for 10:7\n",
    "num_dog_images = 5000\n",
    "num_cat_images = 500\n",
    "\n",
    "# Randomly select the specified number of images\n",
    "selected_dog_indices = random.sample(dog_indices, num_dog_images)\n",
    "selected_cat_indices = random.sample(cat_indices, num_cat_images)\n",
    "\n",
    "print(\"sampled Indeces\")\n",
    "\n",
    "# Combine and shuffle the selected indices\n",
    "selected_indices = selected_dog_indices + selected_cat_indices\n",
    "random.shuffle(selected_indices)\n",
    "\n",
    "# Create the subset dataset\n",
    "subset_dataset = Subset(dataset, selected_indices)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 64\n",
    "dataloader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Verify the dataset sizes\n",
    "print(f\"Number of selected images: {len(subset_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc51e05-b738-475e-9d8e-c63c82efb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# GAN Architecture\n",
    "# --------------------\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, img_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a035b-3560-41a3-af3a-e274c7338c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1437c8-cb6a-45c3-8127-f8854ca53c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "latent_dim = 150\n",
    "generator = Generator(latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb839a-bcdf-4134-ab18-bbe0b34950cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Training Loop\n",
    "# --------------------\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for i, (real_images, _) in enumerate(dataloader):\n",
    "        # Prepare data\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        # Create labels\n",
    "        real_labels = torch.ones(batch_size, device=device)\n",
    "        fake_labels = torch.zeros(batch_size, device=device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        noise = torch.randn(batch_size, latent_dim, 1, 1, device=device)\n",
    "        fake_images = generator(noise)\n",
    "        real_loss = criterion(discriminator(real_images), real_labels)\n",
    "        fake_loss = criterion(discriminator(fake_images.detach()), fake_labels)\n",
    "        d_loss = real_loss + fake_loss\n",
    "        optimizer_d.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Train Generator\n",
    "        noise = torch.randn(batch_size, latent_dim, 1, 1, device=device)\n",
    "        fake_images = generator(noise)\n",
    "        g_loss = criterion(discriminator(fake_images), real_labels)\n",
    "        optimizer_g.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb90ed4d-978d-47ad-9640-1f89ff9d9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Generate Images\n",
    "# --------------------\n",
    "def generate_images(generator, latent_dim, num_images=9):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_images, latent_dim, 1, 1, device=device)\n",
    "        fake_images = generator(noise).cpu()\n",
    "    return fake_images\n",
    "\n",
    "# Generate and display 3x3 grid of images or 5x6 to get more iamges\n",
    "generated_images = generate_images(generator, latent_dim, 9)\n",
    "grid = utils.make_grid(generated_images, nrow=3, normalize=True)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(grid.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "generated_images = generate_images(generator, latent_dim, 9)\n",
    "grid = utils.make_grid(generated_images, nrow=3, normalize=True)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(grid.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c0f30-9f13-4549-82dc-3c8472c11ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Extracting Epochs, D Loss, and G Loss from the provided data\n",
    "# just copy paste the values from the print statements above for d loss and g loss \n",
    "## it would have been easier to just pipe the values during training but seeing their values is lot better for debugging \n",
    "epochs = list(range(1, 101))\n",
    "d_loss = []\n",
    "g_loss = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the graph\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(epochs, d_loss, label=\"Discriminator Loss\", color=\"blue\", alpha=0.7)\n",
    "\n",
    "plt.plot(epochs, g_loss, label=\"Generator Loss\", color=\"orange\", alpha=0.7)\n",
    "\n",
    "plt.axhline(1, color='red', linestyle='--', label='Threshold')\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.title(\"GAN Training y:x: Discriminator Loss vs Generator Loss\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

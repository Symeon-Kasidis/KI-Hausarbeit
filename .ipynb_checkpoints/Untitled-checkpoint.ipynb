{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d2800-61c7-48f9-b64c-b96ffb3f1e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import block\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define all variables here to use later \n",
    "#set to cuda if you have an nvidia GPU. AMD GPUS are not properly supported so just let it to cpu (will take longer to train than gpu)\n",
    "device = torch.device(\"cpu\") \n",
    "#value for one-hot encode. Here it is 2 because that what the docu says binary classification\n",
    "label_dim = 2\n",
    "# Dimension of the random noise vector\n",
    "noise_dim = 100\n",
    "# Define loss function and optimizers\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "#trainings cycles\n",
    "epochs = 50\n",
    "lr = 0.0001\n",
    "beta1 = 0.5\n",
    "latent_dim = 100  # Change this to the desired value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a992a318-b647-4ae0-9284-9d2e803caaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatioDataset(Dataset):\n",
    "    def __init__(self, image_dir, num_dogs, num_cats, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Load dog images\n",
    "        dog_dir = os.path.join(image_dir, \"Dog\")\n",
    "        dog_images = os.listdir(dog_dir)[:num_dogs]\n",
    "        self.image_paths.extend([os.path.join(dog_dir, img) for img in dog_images])\n",
    "        self.labels.extend([1] * len(dog_images))  # 1 for dogs\n",
    "\n",
    "        # Load cat images\n",
    "        cat_dir = os.path.join(image_dir, \"Cat\")\n",
    "        cat_images = os.listdir(cat_dir)[:num_cats]\n",
    "        self.image_paths.extend([os.path.join(cat_dir, img) for img in cat_images])\n",
    "        self.labels.extend([0] * len(cat_images))  # 0 for cats\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d4a72-dbee-4906-933a-9b421493d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),       # Resize to 128x128\n",
    "    transforms.ToTensor(),               # Convert to tensor\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfec4fc-b945-44cb-a013-5150ceecbf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"archive/PetImages\"  # Replace with your dataset's path\n",
    "\n",
    "# Example: 100 dogs and 100 cats\n",
    "dataset = RatioDataset(image_dir=image_dir, num_dogs=100, num_cats=10, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887410ea-1ae8-4eff-a9e6-1092b0ed41f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, label_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(3*128*128 + label_dim, 1024),  # Input is the concatenated image and label\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),  # Output is a single scalar (real or fake)\n",
    "            nn.Sigmoid()  # Sigmoid activation to output a probability\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        x = torch.cat([img.view(img.size(0), -1), labels], dim=1)  # Concatenate image and label\n",
    "        return self.fc(x)  # Output a probability (real or fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c60c7-1614-4d34-84e7-b66e97e1a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, label_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(noise_dim + label_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 3*128*128),  # Output size for a 128x128 image (3 channels for RGB)\n",
    "            nn.Tanh()  # Normalize to the range [-1, 1] (for image data)\n",
    "        )\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        #labels = nn.functional.one_hot(labels, num_classes=label_dim).float()\n",
    "        x = torch.cat([z, labels], dim=1)  # Concatenate noise vector with label vector\n",
    "        return self.fc(x).view(-1, 3, 128, 128)  # Reshape to image size (3 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9add6-9b42-4cd2-8e12-b9aed5713804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def generate_images(generator, label, num_images=6):\n",
    "    generator.eval()\n",
    "    \n",
    "    # Generate noise and labels\n",
    "    noise = torch.randn(num_images, noise_dim, device=device)\n",
    "    one_hot_label = nn.functional.one_hot(torch.tensor([label] * num_images), num_classes=label_dim).float().to(device)\n",
    "    fake_imgs = generator(noise, one_hot_label).detach().cpu()\n",
    "    # Determine grid size (e.g., 2 rows and 3 columns for 6 images)\n",
    "    grid_rows = 2\n",
    "    grid_cols = 3\n",
    "    \n",
    "    # Set up the grid for plotting\n",
    "    fig, axes = plt.subplots(grid_rows, grid_cols, figsize=(10, 7))\n",
    "    axes = axes.flatten()  # Flatten the grid to make indexing easier\n",
    "\n",
    "    # Plot each image on the grid\n",
    "    for i in range(num_images):\n",
    "        img = (fake_imgs[i] + 1) / 2  # Rescale to [0, 1]\n",
    "        img = img.permute(1, 2, 0).numpy()  # Rearrange to (H, W, C) for plotting\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis(\"off\")\n",
    "    \n",
    "    # Remove any unused axes if the grid is larger than num_images\n",
    "    for j in range(num_images, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    # Show the grid\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7c2c8-7504-4ac4-988d-f46232dbfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of epochs\n",
    "epochs = 150  # Adjust as needed\n",
    "\n",
    "generator = Generator(noise_dim, label_dim)\n",
    "discriminator = Discriminator(label_dim)\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for real_imgs, labels in data_loader:\n",
    "        batch_size = real_imgs.size(0)\n",
    "        real_imgs, labels = real_imgs.to(device), labels.to(device)\n",
    "\n",
    "        # One-hot encode labels\n",
    "        one_hot_labels = nn.functional.one_hot(labels, num_classes=label_dim).float().to(device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        noise = torch.randn(batch_size, noise_dim, device=device)\n",
    "        fake_imgs = generator(noise, one_hot_labels)\n",
    "        real_preds = discriminator(real_imgs, one_hot_labels)\n",
    "        fake_preds = discriminator(fake_imgs.detach(), one_hot_labels)\n",
    "        loss_d = criterion(real_preds, torch.ones_like(real_preds)) + \\\n",
    "                 criterion(fake_preds, torch.zeros_like(fake_preds))\n",
    "\n",
    "        optimizer_d.zero_grad()\n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Train Generator\n",
    "        fake_preds = discriminator(fake_imgs, one_hot_labels)\n",
    "        loss_g = criterion(fake_preds, torch.ones_like(fake_preds))\n",
    "\n",
    "        optimizer_g.zero_grad()\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] Loss D: {loss_d:.4f}, Loss G: {loss_g:.4f}\")\n",
    "    if epoch % 10 == 0:\n",
    "        generate_images(generator, label=0, num_images=2)\n",
    "        #generate_images(generator, label=1, num_images=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9102206-50bd-4fce-8cbf-c19d3a0f0abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dog Pictures\")\n",
    "# Generate 5 dog images (label=1)\n",
    "num_images = 6\n",
    "generate_images(generator, label=1, num_images=6)\n",
    "print(\"Cat Pictures\")\n",
    "# Generate 5 cat images (label=0)\n",
    "generate_images(generator, label=0, num_images=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61d4a4-7e18-4f8c-b82a-9fb961b2e85d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
